
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>探索向～iOS视频播放 - 陈浩的技术博客</title>
  <meta name="author" content="Hawk0620">

  
  <meta name="description" content="从体验说起 &emsp;&emsp;对比微信和Instagram可以发现播放视频的两个思路：微信的处理是把视频加载好后播放，这样确保了视频是完整的，用户很直观视频是否下载完成，不影响用户观看视频的体验；而Instagram的做法是边加载边播，当网络不给力的时候，视频就卡在那里， &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://hawk0620.github.io/blog/2015/11/17/ios-play-video">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="陈浩的技术博客" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.useso.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.useso.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.useso.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">陈浩的技术博客</a></h1>
  
    <h2>怕什么真理无穷，进一寸有一寸的欢喜</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:hawk0620.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">探索向～iOS视频播放</h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-11-17T21:50:18+08:00" pubdate data-updated="true">Nov 17<sup>th</sup>, 2015</time>
        
      </p>
    
  </header>


<div class="entry-content"><h4>从体验说起</h4>

<p>&emsp;&emsp;对比微信和Instagram可以发现播放视频的两个思路：微信的处理是把视频加载好后播放，这样确保了视频是完整的，用户很直观视频是否下载完成，不影响用户观看视频的体验；而Instagram的做法是边加载边播，当网络不给力的时候，视频就卡在那里，给用户增加了观看视频的焦虑，并且用户还得自己判断下视频是不是加载完成了，最不幸的是，当视频的网络请求不可达时，不能给出加载失败的提示引导用户重新加载，只能滑动列表触发刷新。</p>

<h4>播放视频的实现</h4>

<p>1、通过实践，我发现Instagram采用的应该是<code>AVPlayer</code>实现的。</p>

<!--more-->


<p><code>AVPlayerItem</code>可以通过远程URL创建出来，并且支持流的形式播放，还可以添加视频播放卡住和视频播放完成的两个观察者：</p>

<pre><code>[[NSNotificationCenter defaultCenter] addObserver:self selector:@selector(itemDidBufferPlaying:) name:AVPlayerItemPlaybackStalledNotification object:nil];
[[NSNotificationCenter defaultCenter] addObserver:self selector:@selector(itemDidFinishPlaying:) name:AVPlayerItemDidPlayToEndTimeNotification object:nil];
</code></pre>

<p>但遗憾的是，我没有找到视频加载失败的观察者。</p>

<p>2、结合微信团队的技术分享<a href="http://mp.weixin.qq.com/s?__biz=MzAwNDY1ODY2OQ==&amp;mid=207686973&amp;idx=1&amp;sn=1883a6c9fa0462dd5596b8890b6fccf6&amp;scene=0#wechat_redirect">链接</a>，得知微信的视频播放是采用<code>AVAssetReader</code>+<code>AVAssetReaderTrackOutput</code>，根据微信的思路，自己也尝试实现了一番：
buffer的转换：</p>

<pre><code>- (CGImageRef) imageFromSampleBuffer:(CMSampleBufferRef) sampleBuffer {
   CVImageBufferRef imageBuffer = CMSampleBufferGetImageBuffer(sampleBuffer);
   // Lock the base address of the pixel buffer
   CVPixelBufferLockBaseAddress(imageBuffer, 0);
   // Get the number of bytes per row for the pixel buffer
   size_t bytesPerRow = CVPixelBufferGetBytesPerRow(imageBuffer);
   // Get the pixel buffer width and height
   size_t width = CVPixelBufferGetWidth(imageBuffer);
   size_t height = CVPixelBufferGetHeight(imageBuffer);
   //Generate image to edit
   unsigned char* pixel = (unsigned char *)CVPixelBufferGetBaseAddress(imageBuffer);
   CGColorSpaceRef colorSpace=CGColorSpaceCreateDeviceRGB();
   CGContextRef context=CGBitmapContextCreate(pixel, width, height, 8, bytesPerRow, colorSpace, kCGBitmapByteOrder32Little|kCGImageAlphaPremultipliedFirst);
   CGImageRef image = CGBitmapContextCreateImage(context);
   CGContextRelease(context);
   CGColorSpaceRelease(colorSpace);
   return image;
}
</code></pre>

<p>视频的解码：</p>

<pre><code>AVURLAsset *asset = [AVURLAsset URLAssetWithURL:[[NSURL alloc] initFileURLWithPath:path] options:nil];
NSError *error;
AVAssetReader* reader = [[AVAssetReader alloc] initWithAsset:asset error:&amp;error];
NSArray* videoTracks = [asset tracksWithMediaType:AVMediaTypeVideo];
AVAssetTrack* videoTrack = [videoTracks objectAtIndex:0];

int m_pixelFormatType = kCVPixelFormatType_32BGRA;
NSDictionary* options = [NSDictionary dictionaryWithObject:[NSNumber numberWithInt: (int)m_pixelFormatType] forKey:(id)kCVPixelBufferPixelFormatTypeKey];
AVAssetReaderTrackOutput* videoReaderOutput = [[AVAssetReaderTrackOutput alloc] initWithTrack:videoTrack outputSettings:options];
[reader addOutput:videoReaderOutput];
[reader startReading];

// 读取视频每一个buffer转换成CGImageRef
dispatch_async(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0), ^{
   CMSampleBufferRef audioSampleBuffer = NULL;
   while ([reader status] == AVAssetReaderStatusReading &amp;&amp; videoTrack.nominalFrameRate &gt; 0) {
   CMSampleBufferRef sampleBuffer = [videoReaderOutput copyNextSampleBuffer];
   CGImageRef image = [self imageFromSampleBuffer:sampleBuffer];
   if (self.delegate &amp;&amp; [self.delegate respondsToSelector:@selector(mMovieDecoder:onNewVideoFrameReady:)]) {
        [self.delegate mMovieDecoder:self onNewVideoFrameReady:image];
    }
   if(sampleBuffer) {
       if(audioSampleBuffer) { // release old buffer.
            CFRelease(audioSampleBuffer);
            audioSampleBuffer = nil;
       }
       audioSampleBuffer = sampleBuffer;
   } else {
       break;
   }

// 休眠的间隙刚好是每一帧的间隔
   [NSThread sleepForTimeInterval:CMTimeGetSeconds(videoTrack.minFrameDuration)];
 }
 // decode finish
 float durationInSeconds = CMTimeGetSeconds(asset.duration);
  if (self.delegate &amp;&amp; [self.delegate respondsToSelector:@selector(mMovieDecoderOnDecodeFinished:duration:)]) {
     [self.delegate mMovieDecoderOnDecodeFinished:self duration:durationInSeconds];
   }
});
</code></pre>

<p>处理每一帧CGImageRef的回调：</p>

<pre><code>- (void)mMovieDecoder:(VideoDecoder *)decoder onNewVideoFrameReady:(CGImageRef)imgRef {
    __weak PlayBackView *weakView = self;
    dispatch_async(dispatch_get_main_queue(), ^{
        weakView.layer.contents = (__bridge id _Nullable)(imgRef);
    });
}
</code></pre>

<p>处理视频解码完成的回调：</p>

<pre><code>images即每一帧传上来的CGImageRef的数组
- (void)mMovieDecoderOnDecodeFinished:(VideoDecoder *)decoder images:(NSArray *)imgs duration:(float)duration {
    __weak PlayBackView *weakView = self;
    dispatch_async(dispatch_get_main_queue(), ^{
        weakView.layer.contents = nil;

        CAKeyframeAnimation *animation = [CAKeyframeAnimation animationWithKeyPath: @"contents"];
        animation.calculationMode = kCAAnimationDiscrete;
        animation.duration = duration;
        animation.repeatCount = HUGE; //循环播放
        animation.values = images; // NSArray of CGImageRefs
        [weakView.layer addAnimation:animation forKey: @"contents"];
    });
}
</code></pre>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Hawk0620</span></span>

      








  


<time datetime="2015-11-17T21:50:18+08:00" pubdate data-updated="true">Nov 17<sup>th</sup>, 2015</time>
      


    </p>
    
      <div class="sharing">
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2015/11/14/record-video-mirror/" title="Previous Post: iOS拍视频前置摄像头翻转的解决">&laquo; iOS拍视频前置摄像头翻转的解决</a>
      
      
        <a class="basic-alignment right" href="/blog/2015/11/21/daymic-tableview-height/" title="Next Post: AutoLayout实现的动态TableView高度">AutoLayout实现的动态TableView高度 &raquo;</a>
      
    </p>
  </footer>
</article>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2016/01/10/protobuf-objc/">Objective-C序列化库protobuf的安装</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/01/03/2015booklist/">2015年我读过的几本书</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/01/01/crop-square-image/">如何实现方形图片裁剪器</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/12/21/nsoperation/">NSOperation初探</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/11/29/fun-with-app-icon/">如何在编译过程中改变app Icon</a>
      </li>
    
  </ul>
</section>





  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2016 - Hawk0620 -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  











</body>
</html>
